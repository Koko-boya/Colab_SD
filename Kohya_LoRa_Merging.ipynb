{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Merging LoRas -> Model"
      ],
      "metadata": {
        "id": "BTNTXTKHlAGz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# Install Kohya Trainer\n",
        "This notebook is completely based on Linaqruf's notebooks available at https://github.com/Linaqruf/kohya-trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u3q60di584x",
        "outputId": "c10ef132-e1de-4484-c744-fee2924e4cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb  3 19:00:41 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Stored 'root_dir' (str)\n",
            "Stored 'repo_dir' (str)\n",
            "Stored 'tools_dir' (str)\n",
            "Stored 'finetune_dir' (str)\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "#@title ## 1.1. Clone Kohya Trainer\n",
        "#@markdown Clone Kohya Trainer from GitHub and check for updates. Use textbox below if you want to checkout other branch or old commit. Leave it empty to stay the HEAD on main.\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "root_dir = \"/content\"\n",
        "%store root_dir\n",
        "repo_dir = str(root_dir)+\"/kohya-trainer\"\n",
        "%store repo_dir\n",
        "tools_dir = str(root_dir)+\"/kohya-trainer/tools\"\n",
        "%store tools_dir \n",
        "finetune_dir = str(root_dir)+\"/kohya-trainer/finetune\"\n",
        "%store finetune_dir\n",
        "\n",
        "branch = \"\" #@param {type: \"string\"}\n",
        "repo_url = \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "\n",
        "def clone_repo():\n",
        "  if os.path.isdir(repo_dir):\n",
        "    print(\"The repository folder already exists, will do a !git pull instead\\n\")\n",
        "    %cd {repo_dir}\n",
        "    !git pull origin {branch} if branch else !git pull\n",
        "  else:\n",
        "    %cd {root_dir}\n",
        "    !git clone {repo_url} {repo_dir}\n",
        "\n",
        "if not os.path.isdir(repo_dir):\n",
        "  clone_repo()\n",
        "\n",
        "%cd {root_dir}\n",
        "os.makedirs(repo_dir, exist_ok=True)\n",
        "os.makedirs(tools_dir, exist_ok=True)\n",
        "os.makedirs(finetune_dir, exist_ok=True)\n",
        "os.makedirs(training_dir, exist_ok=True)\n",
        "\n",
        "if branch:\n",
        "  %cd {repo_dir}\n",
        "  status = os.system(f\"git checkout {branch}\")\n",
        "  if status != 0:\n",
        "    raise Exception(\"Failed to checkout branch or commit\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNn0g1pnHfk5",
        "outputId": "cc84c6b0-ce5a-4683-c173-d4ba45c82ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'accelerate_config' (str)\n",
            "/content/kohya-trainer\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.5/581.5 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-510\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2 lz4\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 liblz4-tool lz4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 1,562 kB of archives.\n",
            "After this operation, 6,198 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libc-ares2 amd64 1.15.0-1ubuntu0.1 [38.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libaria2-0 amd64 1.35.0-1build1 [1,082 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 aria2 amd64 1.35.0-1build1 [356 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 lz4 amd64 1.9.2-2ubuntu0.20.04.1 [82.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 liblz4-tool all 1.9.2-2ubuntu0.20.04.1 [2,524 B]\n",
            "Fetched 1,562 kB in 1s (1,133 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 129496 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.15.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.15.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.35.0-1build1_amd64.deb ...\n",
            "Unpacking aria2 (1.35.0-1build1) ...\n",
            "Selecting previously unselected package lz4.\n",
            "Preparing to unpack .../lz4_1.9.2-2ubuntu0.20.04.1_amd64.deb ...\n",
            "Unpacking lz4 (1.9.2-2ubuntu0.20.04.1) ...\n",
            "Selecting previously unselected package liblz4-tool.\n",
            "Preparing to unpack .../liblz4-tool_1.9.2-2ubuntu0.20.04.1_all.deb ...\n",
            "Unpacking liblz4-tool (1.9.2-2ubuntu0.20.04.1) ...\n",
            "Setting up libc-ares2:amd64 (1.15.0-1ubuntu0.1) ...\n",
            "Setting up lz4 (1.9.2-2ubuntu0.20.04.1) ...\n",
            "Setting up liblz4-tool (1.9.2-2ubuntu0.20.04.1) ...\n",
            "Setting up libaria2-0:amd64 (1.35.0-1build1) ...\n",
            "Setting up aria2 (1.35.0-1build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.1/503.1 KB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 KB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.9/102.9 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title ## 1.2. Installing Dependencies\n",
        "#@markdown This will install required Python packages\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "%store accelerate_config\n",
        "install_xformers = True #@param {'type':'boolean'}\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "def install_dependencies():\n",
        "    !pip -q install --upgrade gallery-dl gdown imjoy-elfinder\n",
        "    !apt -q install liblz4-tool aria2\n",
        "    !pip -q install --upgrade -r requirements.txt\n",
        "\n",
        "    if install_xformers:\n",
        "        !pip -q install -U -I --no-deps https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "install_dependencies()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.3. Mount Drive\n",
        "from google.colab import drive\n",
        "\n",
        "mount_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "if mount_drive:\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sKL38-WmQsLN",
        "outputId": "c6286828-4fd3-4b8a-dd88-39766b1c6272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.4. Download Available Model \n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "installModels = []\n",
        "installv2Models = []\n",
        "\n",
        "#@markdown ### Available Model\n",
        "#@markdown Select one of available model to download:\n",
        "\n",
        "#@markdown ### SD1.x model\n",
        "modelUrl = [\"\", \\\n",
        "            \"https://huggingface.co/Linaqruf/personal-backup/resolve/main/models/animefull-final-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors\", \\\n",
        "            \"https://huggingface.co/andite/anything-v4.0/resolve/main/anything-v4.5-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/Rasgeath/self_made_sauce/resolve/main/Kani-anime-pruned.ckpt\", \\\n",
        "            \"https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_nsfw.safetensors\", \\\n",
        "            \"https://huggingface.co/gsdf/Counterfeit-V2.0/resolve/main/Counterfeit-V2.0fp16.safetensors\", \\\n",
        "            \"https://huggingface.co/closertodeath/dpepteahands3/resolve/main/dpepteahand3.ckpt\", \\\n",
        "            \"https://huggingface.co/prompthero/openjourney-v2/resolve/main/openjourney-v2.ckpt\", \\\n",
        "            \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \\\n",
        "            \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\"]\n",
        "modelList = [\"\", \\\n",
        "             \"Animefull-final-pruned\", \\\n",
        "             \"Anything-v3-1\", \\\n",
        "             \"Anything-v4-5-pruned\", \\\n",
        "             \"Kani-anime-pruned\", \\\n",
        "             \"AbyssOrangeMix2-nsfw\", \\\n",
        "             \"Counterfeit-v2\", \\\n",
        "             \"DpepTeaHands3\", \\\n",
        "             \"OpenJourney-v2\", \\\n",
        "             \"Dreamlike-diffusion-v1-0\", \\\n",
        "             \"Stable-Diffusion-v1-5\"]\n",
        "modelName = \"Anything-v4-5-pruned\"  #@param [\"\", \"Animefull-final-pruned\", \"Anything-v3-1\", \"Anything-v4-5-pruned\", \"Kani-anime-pruned\", \"AbyssOrangeMix2-nsfw\", \"Counterfeit-v2\", \"DpepTeaHands3\", \"OpenJourney-v2\", \"Dreamlike-diffusion-v1-0\", \"Stable-Diffusion-v1-5\"]\n",
        "\n",
        "#@markdown ### SD2.x model\n",
        "v2ModelUrl = [\"\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \\\n",
        "              \"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt\", \\\n",
        "              \"https://huggingface.co/p1atdev/pd-archive/resolve/main/plat-v1-3-1.safetensors\"]\n",
        "v2ModelList = [\"\", \\\n",
        "              \"stable-diffusion-2-1-base\", \\\n",
        "              \"stable-diffusion-2-1-768v\", \\\n",
        "              \"waifu-diffusion-1-4-anime-e2\", \\\n",
        "              \"plat-diffusion-v1-3-1\"]\n",
        "v2ModelName = \"\" #@param [\"\", \"stable-diffusion-2-1-base\", \"stable-diffusion-2-1-768v\", \"waifu-diffusion-1-4-anime-e2\", \"plat-diffusion-v1-3-1\"]\n",
        "\n",
        "if modelName != \"\":\n",
        "  installModels.append((modelName, modelUrl[modelList.index(modelName)]))\n",
        "if v2ModelName != \"\":\n",
        "  installv2Models.append((v2ModelName, v2ModelUrl[v2ModelList.index(v2ModelName)]))\n",
        "\n",
        "def install(checkpoint_name, url):\n",
        "  ext = \"ckpt\" if url.endswith(\".ckpt\") else \"safetensors\"\n",
        "\n",
        "  hf_token = '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' \n",
        "  user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "  !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {root_dir}/models -o {checkpoint_name}.{ext} \"{url}\"\n",
        "\n",
        "def install_checkpoint():\n",
        "  for model in installModels:\n",
        "    install(model[0], model[1])\n",
        "  for v2model in installv2Models:\n",
        "    install(v2model[0], v2model[1])\n",
        "\n",
        "install_checkpoint()"
      ],
      "metadata": {
        "id": "wmnsZwClN1XL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ee4bea-ab98-4773-a9ff-3fdecd692481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            " *** Download Progress Summary as of Fri Feb  3 18:59:05 2023 *** \n",
            "=\n",
            "[#cb2f17 2.4GiB/3.9GiB(62%) CN:16 DL:242MiB ETA:6s]\n",
            "FILE: /content/models/Anything-v4-5-pruned.ckpt\n",
            "-\n",
            "\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "cb2f17|\u001b[1;32mOK\u001b[0m  |   243MiB/s|/content/models/Anything-v4-5-pruned.ckpt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## 1.5. Download LoRa\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "#@markdown ### Custom model\n",
        "loraUrl = \"https://huggingface.co/YoungMasterFromSect/Trauter_LoRAs/resolve/main/LoRA/Genshin-Impact/yae%20miko/yae%20miko_Mediumpruned.safetensors\" #@param {'type': 'string'}\n",
        "dst = str(root_dir)+\"/models\"\n",
        "\n",
        "if not os.path.exists(dst):\n",
        "    os.makedirs(dst)\n",
        "\n",
        "def install(url):\n",
        "  base_name = os.path.basename(url)\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    %cd {dst}\n",
        "    !gdown --fuzzy {url}\n",
        "  elif url.startswith(\"https://huggingface.co/\"):\n",
        "    if '/blob/' in url:\n",
        "      url = url.replace('/blob/', '/resolve/')\n",
        "    #@markdown Change this part with your own huggingface token if you need to download your private model\n",
        "    hf_token = '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' #@param {type:\"string\"}\n",
        "    user_header = f\"\\\"Authorization: Bearer {hf_token}\\\"\"\n",
        "    !aria2c --console-log-level=error --summary-interval=10 --header={user_header} -c -x 16 -k 1M -s 16 -d {dst} -o {base_name} {url}\n",
        "  else:\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -d {dst} -o {url}\n",
        "\n",
        "install(loraUrl)\n"
      ],
      "metadata": {
        "id": "3LWn6GzNQ4j5",
        "outputId": "ac94546d-4a6a-441c-b49a-0d606178b069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "76f977|\u001b[1;32mOK\u001b[0m  |   200MiB/s|/content/models/yae%20miko_Mediumpruned.safetensors\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### LoRa Merging\n",
        "import os\n",
        "\n",
        "model = \"/content/pre_trained_model/Anything-v4-5-pruned.ckpt\" #@param {type:\"string\"}\n",
        "save_to = \"/content/drive/MyDrive/mergedlora.ckpt\" #@param {type:\"string\"}\n",
        "loras = \"/content/pre_trained_model/Mona_mediumpruned.safetensors /content/pre_trained_model/yaemiko_Mediumpruned.safetensors\" #@param {'type':'string'}\n",
        "ratio = \"0.75 0.75\" #@param {type:\"string\"}\n",
        "\n",
        "os.chdir('/content/kohya-trainer/networks')\n",
        "!python merge_lora.py \\\n",
        "--sd_model {model} \\\n",
        "--save_to {save_to} \\\n",
        "--models {loras} \\\n",
        "--ratios {ratio}"
      ],
      "metadata": {
        "id": "pKOLC9HMXPci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
